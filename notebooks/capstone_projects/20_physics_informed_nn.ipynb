{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bd1e78",
   "metadata": {},
   "source": [
    "# Location: notebooks/capstone_projects/20_physics_informed_nn.ipynb\n",
    "\n",
    "## Physics-Informed Neural Networks (PINNs) in JAX\n",
    "\n",
    "This capstone project implements Physics-Informed Neural Networks for solving partial differential equations (PDEs) by incorporating physical laws directly into the loss function using automatic differentiation.\n",
    "\n",
    "## Introduction to PINNs\n",
    "\n",
    "Physics-Informed Neural Networks combine the function approximation capabilities of neural networks with the physical constraints encoded in differential equations. This approach allows us to solve PDEs without requiring large datasets, instead using the physics itself as a regularizer.\n",
    "\n",
    "```python\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jit, random\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "# Basic PINN architecture\n",
    "def create_pinn_model(layer_sizes, activation=jax.nn.tanh):\n",
    "    \"\"\"Create a Physics-Informed Neural Network\"\"\"\n",
    "    \n",
    "    def init_params(key):\n",
    "        \"\"\"Initialize network parameters\"\"\"\n",
    "        keys = random.split(key, len(layer_sizes) - 1)\n",
    "        params = []\n",
    "        \n",
    "        for i, (in_size, out_size) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            # Xavier initialization\n",
    "            scale = jnp.sqrt(2.0 / (in_size + out_size))\n",
    "            w = random.normal(keys[i], (in_size, out_size)) * scale\n",
    "            b = jnp.zeros(out_size)\n",
    "            params.append({'w': w, 'b': b})\n",
    "        \n",
    "        return params\n",
    "    \n",
    "    def forward(params, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        h = x\n",
    "        for i, layer in enumerate(params[:-1]):\n",
    "            h = h @ layer['w'] + layer['b']\n",
    "            h = activation(h)\n",
    "        \n",
    "        # Final layer (linear)\n",
    "        final_layer = params[-1]\n",
    "        output = h @ final_layer['w'] + final_layer['b']\n",
    "        return output\n",
    "    \n",
    "    return init_params, forward\n",
    "\n",
    "# Test basic PINN architecture\n",
    "init_pinn, pinn_forward = create_pinn_model([2, 50, 50, 50, 1])\n",
    "params = init_pinn(random.PRNGKey(42))\n",
    "\n",
    "# Test forward pass\n",
    "test_input = jnp.array([[0.5, 0.3], [1.0, 0.7]])\n",
    "test_output = pinn_forward(params, test_input)\n",
    "\n",
    "print(\"PINN Architecture Test:\")\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {test_output.shape}\")\n",
    "print(f\"Number of parameters per layer: {[layer['w'].size + layer['b'].size for layer in params]}\")\n",
    "print(f\"Total parameters: {sum(layer['w'].size + layer['b'].size for layer in params)}\")\n",
    "```\n",
    "\n",
    "## Solving the 1D Heat Equation\n",
    "\n",
    "```python\n",
    "def create_heat_equation_pinn():\n",
    "    \"\"\"Solve 1D heat equation: ∂u/∂t = α ∂²u/∂x²\"\"\"\n",
    "    \n",
    "    # Initialize PINN for heat equation\n",
    "    # Input: [x, t], Output: [u(x,t)]\n",
    "    init_params, forward = create_pinn_model([2, 64, 64, 64, 1])\n",
    "    \n",
    "    def pinn_forward_with_derivatives(params, x, t):\n",
    "        \"\"\"Forward pass with automatic differentiation\"\"\"\n",
    "        \n",
    "        def u_net(x, t):\n",
    "            \"\"\"Network approximation of u(x,t)\"\"\"\n",
    "            inputs = jnp.array([x, t])\n",
    "            return forward(params, inputs.reshape(1, -1))[0, 0]\n",
    "        \n",
    "        # First derivatives\n",
    "        u_t = grad(u_net, argnums=1)(x, t)  # ∂u/∂t\n",
    "        u_x = grad(u_net, argnums=0)(x, t)  # ∂u/∂x\n",
    "        \n",
    "        # Second derivative\n",
    "        u_xx = grad(grad(u_net, argnums=0), argnums=0)(x, t)  # ∂²u/∂x²\n",
    "        \n",
    "        u_val = u_net(x, t)\n",
    "        \n",
    "        return u_val, u_t, u_x, u_xx\n",
    "    \n",
    "    def heat_pde_residual(params, x, t, alpha=0.01):\n",
    "        \"\"\"Compute PDE residual: ∂u/∂t - α ∂²u/∂x²\"\"\"\n",
    "        u_val, u_t, u_x, u_xx = pinn_forward_with_derivatives(params, x, t)\n",
    "        residual = u_t - alpha * u_xx\n",
    "        return residual\n",
    "    \n",
    "    def boundary_condition(params, t):\n",
    "        \"\"\"Boundary conditions: u(0,t) = u(1,t) = 0\"\"\"\n",
    "        u_0, _, _, _ = pinn_forward_with_derivatives(params, 0.0, t)\n",
    "        u_1, _, _, _ = pinn_forward_with_derivatives(params, 1.0, t)\n",
    "        return u_0, u_1\n",
    "    \n",
    "    def initial_condition(params, x):\n",
    "        \"\"\"Initial condition: u(x,0) = sin(π*x)\"\"\"\n",
    "        u_val, _, _, _ = pinn_forward_with_derivatives(params, x, 0.0)\n",
    "        true_initial = jnp.sin(jnp.pi * x)\n",
    "        return u_val - true_initial\n",
    "    \n",
    "    def pinn_loss(params, x_pde, t_pde, x_bc, t_bc, x_ic, \n",
    "                  lambda_pde=1.0, lambda_bc=1.0, lambda_ic=1.0):\n",
    "        \"\"\"Total PINN loss combining PDE, boundary, and initial conditions\"\"\"\n",
    "        \n",
    "        # PDE residual loss\n",
    "        pde_residuals = vmap(lambda x, t: heat_pde_residual(params, x, t))(x_pde, t_pde)\n",
    "        pde_loss = jnp.mean(pde_residuals**2)\n",
    "        \n",
    "        # Boundary condition loss\n",
    "        bc_residuals = vmap(lambda t: boundary_condition(params, t))(t_bc)\n",
    "        bc_loss = jnp.mean(bc_residuals[0]**2) + jnp.mean(bc_residuals[1]**2)\n",
    "        \n",
    "        # Initial condition loss  \n",
    "        ic_residuals = vmap(lambda x: initial_condition(params, x))(x_ic)\n",
    "        ic_loss = jnp.mean(ic_residuals**2)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (lambda_pde * pde_loss + \n",
    "                     lambda_bc * bc_loss + \n",
    "                     lambda_ic * ic_loss)\n",
    "        \n",
    "        return total_loss, {\n",
    "            'pde_loss': pde_loss,\n",
    "            'bc_loss': bc_loss, \n",
    "            'ic_loss': ic_loss,\n",
    "            'total_loss': total_loss\n",
    "        }\n",
    "    \n",
    "    return init_params, pinn_forward_with_derivatives, pinn_loss\n",
    "\n",
    "# Create heat equation PINN\n",
    "init_heat_params, heat_forward, heat_loss_fn = create_heat_equation_pinn()\n",
    "heat_params = init_heat_params(random.PRNGKey(123))\n",
    "\n",
    "# Generate training data points\n",
    "key = random.PRNGKey(456)\n",
    "n_pde = 10000\n",
    "n_bc = 100  \n",
    "n_ic = 100\n",
    "\n",
    "# PDE collocation points (interior)\n",
    "x_pde = random.uniform(key, (n_pde,)) * 1.0  # x ∈ [0, 1]\n",
    "t_pde = random.uniform(random.split(key)[0], (n_pde,)) * 0.5  # t ∈ [0, 0.5]\n",
    "\n",
    "# Boundary points (x=0 and x=1 for all t)\n",
    "t_bc = random.uniform(random.split(key)[1], (n_bc,)) * 0.5\n",
    "\n",
    "# Initial condition points (t=0 for all x)\n",
    "x_ic = random.uniform(random.split(key)[2], (n_ic,)) * 1.0\n",
    "\n",
    "print(\"Heat Equation PINN Setup:\")\n",
    "print(f\"PDE collocation points: {n_pde}\")\n",
    "print(f\"Boundary condition points: {n_bc}\")\n",
    "print(f\"Initial condition points: {n_ic}\")\n",
    "\n",
    "# Test loss computation\n",
    "loss, info = heat_loss_fn(heat_params, x_pde, t_pde, x_ic, t_bc, x_ic)\n",
    "print(f\"\\nInitial losses:\")\n",
    "print(f\"Total loss: {loss:.6f}\")\n",
    "print(f\"PDE loss: {info['pde_loss']:.6f}\")\n",
    "print(f\"BC loss: {info['bc_loss']:.6f}\")\n",
    "print(f\"IC loss: {info['ic_loss']:.6f}\")\n",
    "```\n",
    "\n",
    "## Training the Heat Equation PINN\n",
    "\n",
    "```python\n",
    "def train_heat_pinn(init_params, loss_fn, training_data, n_epochs=5000, lr=1e-3):\n",
    "    \"\"\"Train the heat equation PINN\"\"\"\n",
    "    \n",
    "    x_pde, t_pde, x_bc, t_bc, x_ic = training_data\n",
    "    \n",
    "    # Initialize optimizer (Adam)\n",
    "    def init_adam(params):\n",
    "        return {\n",
    "            'm': jax.tree_map(jnp.zeros_like, params),\n",
    "            'v': jax.tree_map(jnp.zeros_like, params),\n",
    "            'step': 0\n",
    "        }\n",
    "    \n",
    "    def adam_update(params, grads, opt_state, lr=1e-3, beta1=0.9, beta2=0.999, eps=1e-8):\n",
    "        step = opt_state['step'] + 1\n",
    "        \n",
    "        # Update biased first and second moment estimates\n",
    "        m = jax.tree_map(lambda m, g: beta1 * m + (1 - beta1) * g, opt_state['m'], grads)\n",
    "        v = jax.tree_map(lambda v, g: beta2 * v + (1 - beta2) * g**2, opt_state['v'], grads)\n",
    "        \n",
    "        # Bias correction\n",
    "        m_hat = jax.tree_map(lambda m: m / (1 - beta1**step), m)\n",
    "        v_hat = jax.tree_map(lambda v: v / (1 - beta2**step), v)\n",
    "        \n",
    "        # Parameter update\n",
    "        new_params = jax.tree_map(\n",
    "            lambda p, m, v: p - lr * m / (jnp.sqrt(v) + eps),\n",
    "            params, m_hat, v_hat\n",
    "        )\n",
    "        \n",
    "        new_opt_state = {'m': m, 'v': v, 'step': step}\n",
    "        return new_params, new_opt_state\n",
    "    \n",
    "    @jit\n",
    "    def train_step(params, opt_state):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        loss, info = loss_fn(params, x_pde, t_pde, x_bc, t_bc, x_ic)\n",
    "        grads = grad(lambda p: loss_fn(p, x_pde, t_pde, x_bc, t_bc, x_ic)[0])(params)\n",
    "        \n",
    "        new_params, new_opt_state = adam_update(params, grads, opt_state, lr)\n",
    "        return new_params, new_opt_state, loss, info\n",
    "    \n",
    "    # Training loop\n",
    "    params = init_params\n",
    "    opt_state = init_adam(params)\n",
    "    losses = []\n",
    "    \n",
    "    print(\"Training Heat Equation PINN:\")\n",
    "    print(\"Epoch | Total Loss | PDE Loss  | BC Loss   | IC Loss\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        params, opt_state, loss, info = train_step(params, opt_state)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"{epoch:5d} | {loss:9.6f} | {info['pde_loss']:8.6f} | \"\n",
    "                  f\"{info['bc_loss']:8.6f} | {info['ic_loss']:8.6f}\")\n",
    "    \n",
    "    print(f\"\\nFinal loss: {losses[-1]:.6f}\")\n",
    "    return params, losses\n",
    "\n",
    "# Train the PINN\n",
    "training_data = (x_pde, t_pde, x_bc, t_bc, x_ic)\n",
    "trained_params, training_losses = train_heat_pinn(\n",
    "    heat_params, heat_loss_fn, training_data, n_epochs=2000, lr=1e-3\n",
    ")\n",
    "\n",
    "# Analytical solution for comparison\n",
    "def analytical_heat_solution(x, t, alpha=0.01):\n",
    "    \"\"\"Analytical solution: u(x,t) = sin(π*x) * exp(-π²*α*t)\"\"\"\n",
    "    return jnp.sin(jnp.pi * x) * jnp.exp(-jnp.pi**2 * alpha * t)\n",
    "\n",
    "# Test trained PINN\n",
    "test_x = jnp.linspace(0, 1, 50)\n",
    "test_t = jnp.array([0.0, 0.1, 0.2, 0.3])\n",
    "\n",
    "print(\"\\nTesting Trained PINN:\")\n",
    "print(\"x    | t    | PINN     | Analytical | Error\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for t_val in test_t:\n",
    "    for i, x_val in enumerate(test_x[::10]):  # Sample every 10th point\n",
    "        pinn_val, _, _, _ = heat_forward(trained_params, x_val, t_val)\n",
    "        analytical_val = analytical_heat_solution(x_val, t_val)\n",
    "        error = abs(pinn_val - analytical_val)\n",
    "        \n",
    "        print(f\"{x_val:.1f} | {t_val:.1f} | {pinn_val:8.5f} | {analytical_val:8.5f} | {error:.5f}\")\n",
    "    if t_val < test_t[-1]:\n",
    "        print(\"-\" * 45)\n",
    "```\n",
    "\n",
    "## Solving the 2D Poisson Equation\n",
    "\n",
    "```python\n",
    "def create_poisson_equation_pinn():\n",
    "    \"\"\"Solve 2D Poisson equation: ∇²u = f(x,y)\"\"\"\n",
    "    \n",
    "    # Network: Input [x, y], Output [u(x,y)]\n",
    "    init_params, forward = create_pinn_model([2, 100, 100, 100, 1])\n",
    "    \n",
    "    def poisson_pinn_forward(params, x, y):\n",
    "        \"\"\"Forward pass with second derivatives\"\"\"\n",
    "        \n",
    "        def u_net(x, y):\n",
    "            inputs = jnp.array([x, y])\n",
    "            return forward(params, inputs.reshape(1, -1))[0, 0]\n",
    "        \n",
    "        # First derivatives\n",
    "        u_x = grad(u_net, argnums=0)(x, y)\n",
    "        u_y = grad(u_net, argnums=1)(x, y)\n",
    "        \n",
    "        # Second derivatives\n",
    "        u_xx = grad(grad(u_net, argnums=0), argnums=0)(x, y)\n",
    "        u_yy = grad(grad(u_net, argnums=1), argnums=1)(x, y)\n",
    "        \n",
    "        u_val = u_net(x, y)\n",
    "        laplacian = u_xx + u_yy  # ∇²u\n",
    "        \n",
    "        return u_val, u_x, u_y, laplacian\n",
    "    \n",
    "    def source_function(x, y):\n",
    "        \"\"\"Source term: f(x,y) = -2π² sin(πx) sin(πy)\"\"\"\n",
    "        return -2 * jnp.pi**2 * jnp.sin(jnp.pi * x) * jnp.sin(jnp.pi * y)\n",
    "    \n",
    "    def poisson_pde_residual(params, x, y):\n",
    "        \"\"\"PDE residual: ∇²u - f(x,y)\"\"\"\n",
    "        u_val, u_x, u_y, laplacian = poisson_pinn_forward(params, x, y)\n",
    "        f_val = source_function(x, y)\n",
    "        residual = laplacian - f_val\n",
    "        return residual\n",
    "    \n",
    "    def dirichlet_bc(params, x, y):\n",
    "        \"\"\"Dirichlet boundary condition: u = 0 on boundary\"\"\"\n",
    "        u_val, _, _, _ = poisson_pinn_forward(params, x, y)\n",
    "        return u_val\n",
    "    \n",
    "    def poisson_loss(params, x_pde, y_pde, x_bc, y_bc, lambda_pde=1.0, lambda_bc=1.0):\n",
    "        \"\"\"Total loss for Poisson equation\"\"\"\n",
    "        \n",
    "        # PDE residual loss\n",
    "        pde_residuals = vmap(lambda x, y: poisson_pde_residual(params, x, y))(x_pde, y_pde)\n",
    "        pde_loss = jnp.mean(pde_residuals**2)\n",
    "        \n",
    "        # Boundary condition loss\n",
    "        bc_residuals = vmap(lambda x, y: dirichlet_bc(params, x, y))(x_bc, y_bc)\n",
    "        bc_loss = jnp.mean(bc_residuals**2)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = lambda_pde * pde_loss + lambda_bc * bc_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            'pde_loss': pde_loss,\n",
    "            'bc_loss': bc_loss,\n",
    "            'total_loss': total_loss\n",
    "        }\n",
    "    \n",
    "    return init_params, poisson_pinn_forward, poisson_loss\n",
    "\n",
    "# Create Poisson PINN\n",
    "init_poisson_params, poisson_forward, poisson_loss_fn = create_poisson_equation_pinn()\n",
    "poisson_params = init_poisson_params(random.PRNGKey(789))\n",
    "\n",
    "# Generate training data for 2D domain [0,1] × [0,1]\n",
    "key = random.PRNGKey(101112)\n",
    "n_pde_2d = 10000\n",
    "n_bc_2d = 1000\n",
    "\n",
    "# Interior points\n",
    "x_pde_2d = random.uniform(key, (n_pde_2d,))\n",
    "y_pde_2d = random.uniform(random.split(key)[0], (n_pde_2d,))\n",
    "\n",
    "# Boundary points (edges of unit square)\n",
    "def generate_boundary_points(key, n_points):\n",
    "    \"\"\"Generate points on boundary of unit square\"\"\"\n",
    "    keys = random.split(key, 4)\n",
    "    n_per_edge = n_points // 4\n",
    "    \n",
    "    # Bottom edge: y = 0\n",
    "    x_bottom = random.uniform(keys[0], (n_per_edge,))\n",
    "    y_bottom = jnp.zeros(n_per_edge)\n",
    "    \n",
    "    # Top edge: y = 1\n",
    "    x_top = random.uniform(keys[1], (n_per_edge,))\n",
    "    y_top = jnp.ones(n_per_edge)\n",
    "    \n",
    "    # Left edge: x = 0\n",
    "    x_left = jnp.zeros(n_per_edge)\n",
    "    y_left = random.uniform(keys[2], (n_per_edge,))\n",
    "    \n",
    "    # Right edge: x = 1\n",
    "    x_right = jnp.ones(n_per_edge)\n",
    "    y_right = random.uniform(keys[3], (n_per_edge,))\n",
    "    \n",
    "    x_bc = jnp.concatenate([x_bottom, x_top, x_left, x_right])\n",
    "    y_bc = jnp.concatenate([y_bottom, y_top, y_left, y_right])\n",
    "    \n",
    "    return x_bc, y_bc\n",
    "\n",
    "x_bc_2d, y_bc_2d = generate_boundary_points(random.split(key)[1], n_bc_2d)\n",
    "\n",
    "# Test Poisson loss\n",
    "poisson_loss, poisson_info = poisson_loss_fn(poisson_params, x_pde_2d, y_pde_2d, x_bc_2d, y_bc_2d)\n",
    "\n",
    "print(\"2D Poisson Equation PINN Setup:\")\n",
    "print(f\"Interior PDE points: {n_pde_2d}\")\n",
    "print(f\"Boundary points: {len(x_bc_2d)}\")\n",
    "print(f\"Initial total loss: {poisson_loss:.6f}\")\n",
    "print(f\"Initial PDE loss: {poisson_info['pde_loss']:.6f}\")\n",
    "print(f\"Initial BC loss: {poisson_info['bc_loss']:.6f}\")\n",
    "\n",
    "# Analytical solution for Poisson equation\n",
    "def analytical_poisson_solution(x, y):\n",
    "    \"\"\"Analytical solution: u(x,y) = sin(πx) sin(πy)\"\"\"\n",
    "    return jnp.sin(jnp.pi * x) * jnp.sin(jnp.pi * y)\n",
    "\n",
    "# Quick training (fewer epochs for demonstration)\n",
    "def train_poisson_pinn(params, loss_fn, x_pde, y_pde, x_bc, y_bc, n_epochs=1000):\n",
    "    \"\"\"Train Poisson PINN\"\"\"\n",
    "    \n",
    "    @jit\n",
    "    def train_step(params, lr=1e-3):\n",
    "        loss, info = loss_fn(params, x_pde, y_pde, x_bc, y_bc)\n",
    "        grads = grad(lambda p: loss_fn(p, x_pde, y_pde, x_bc, y_bc)[0])(params)\n",
    "        new_params = jax.tree_map(lambda p, g: p - lr * g, params, grads)\n",
    "        return new_params, loss, info\n",
    "    \n",
    "    print(\"\\nTraining 2D Poisson PINN:\")\n",
    "    current_params = params\n",
    "    \n",
    "    for epoch in range(0, n_epochs, 200):  # Every 200 epochs\n",
    "        current_params, loss, info = train_step(current_params)\n",
    "        print(f\"Epoch {epoch:4d}: Total={loss:.6f}, PDE={info['pde_loss']:.6f}, BC={info['bc_loss']:.6f}\")\n",
    "    \n",
    "    return current_params\n",
    "\n",
    "# Train Poisson PINN\n",
    "trained_poisson_params = train_poisson_pinn(\n",
    "    poisson_params, poisson_loss_fn, x_pde_2d, y_pde_2d, x_bc_2d, y_bc_2d, n_epochs=1000\n",
    ")\n",
    "\n",
    "# Test on grid\n",
    "test_x_grid = jnp.linspace(0, 1, 11)\n",
    "test_y_grid = jnp.linspace(0, 1, 11) \n",
    "\n",
    "print(\"\\n2D Poisson Solution Comparison (sample points):\")\n",
    "print(\"x    | y    | PINN      | Analytical | Error\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(0, len(test_x_grid), 2):  # Sample every other point\n",
    "    for j in range(0, len(test_y_grid), 2):\n",
    "        x_val, y_val = test_x_grid[i], test_y_grid[j]\n",
    "        pinn_val, _, _, _ = poisson_forward(trained_poisson_params, x_val, y_val)\n",
    "        analytical_val = analytical_poisson_solution(x_val, y_val)\n",
    "        error = abs(pinn_val - analytical_val)\n",
    "        \n",
    "        print(f\"{x_val:.1f} | {y_val:.1f} | {pinn_val:9.6f} | {analytical_val:9.6f} | {error:.6f}\")\n",
    "```\n",
    "\n",
    "## Advanced PINN: Navier-Stokes Equations\n",
    "\n",
    "```python\n",
    "def create_navier_stokes_pinn():\n",
    "    \"\"\"Solve 2D incompressible Navier-Stokes equations\"\"\"\n",
    "    \n",
    "    # Network outputs: [u, v, p] (velocity components and pressure)\n",
    "    init_params, forward = create_pinn_model([3, 128, 128, 128, 128, 3])  # Input: [x, y, t]\n",
    "    \n",
    "    def ns_forward(params, x, y, t):\n",
    "        \"\"\"Forward pass with all required derivatives\"\"\"\n",
    "        \n",
    "        def uvp_net(x, y, t):\n",
    "            inputs = jnp.array([x, y, t])\n",
    "            output = forward(params, inputs.reshape(1, -1))[0]\n",
    "            return output[0], output[1], output[2]  # u, v, p\n",
    "        \n",
    "        # Velocity and pressure values\n",
    "        u, v, p = uvp_net(x, y, t)\n",
    "        \n",
    "        # First derivatives of u\n",
    "        u_x = grad(lambda x, y, t: uvp_net(x, y, t)[0], argnums=0)(x, y, t)\n",
    "        u_y = grad(lambda x, y, t: uvp_net(x, y, t)[0], argnums=1)(x, y, t)\n",
    "        u_t = grad(lambda x, y, t: uvp_net(x, y, t)[0], argnums=2)(x, y, t)\n",
    "        \n",
    "        # First derivatives of v\n",
    "        v_x = grad(lambda x, y, t: uvp_net(x, y, t)[1], argnums=0)(x, y, t)\n",
    "        v_y = grad(lambda x, y, t: uvp_net(x, y, t)[1], argnums=1)(x, y, t)\n",
    "        v_t = grad(lambda x, y, t: uvp_net(x, y, t)[1], argnums=2)(x, y, t)\n",
    "        \n",
    "        # Pressure derivatives\n",
    "        p_x = grad(lambda x, y, t: uvp_net(x, y, t)[2], argnums=0)(x, y, t)\n",
    "        p_y = grad(lambda x, y, t: uvp_net(x, y, t)[2], argnums=1)(x, y, t)\n",
    "        \n",
    "        # Second derivatives of u\n",
    "        u_xx = grad(grad(lambda x, y, t: uvp_net(x, y, t)[0], argnums=0), argnums=0)(x, y, t)\n",
    "        u_yy = grad(grad(lambda x, y, t: uvp_net(x, y, t)[0], argnums=1), argnums=1)(x, y, t)\n",
    "        \n",
    "        # Second derivatives of v  \n",
    "        v_xx = grad(grad(lambda x, y, t: uvp_net(x, y, t)[1], argnums=0), argnums=0)(x, y, t)\n",
    "        v_yy = grad(grad(lambda x, y, t: uvp_net(x, y, t)[1], argnums=1), argnums=1)(x, y, t)\n",
    "        \n",
    "        return {\n",
    "            'u': u, 'v': v, 'p': p,\n",
    "            'u_x': u_x, 'u_y': u_y, 'u_t': u_t,\n",
    "            'v_x': v_x, 'v_y': v_y, 'v_t': v_t,\n",
    "            'p_x': p_x, 'p_y': p_y,\n",
    "            'u_xx': u_xx, 'u_yy': u_yy,\n",
    "            'v_xx': v_xx, 'v_yy': v_yy\n",
    "        }\n",
    "    \n",
    "    def navier_stokes_residuals(params, x, y, t, Re=100.0):\n",
    "        \"\"\"Compute Navier-Stokes equation residuals\"\"\"\n",
    "        \n",
    "        derivatives = ns_forward(params, x, y, t)\n",
    "        \n",
    "        # Continuity equation: ∂u/∂x + ∂v/∂y = 0\n",
    "        continuity = derivatives['u_x'] + derivatives['v_y']\n",
    "        \n",
    "        # Momentum equations\n",
    "        # ∂u/∂t + u∂u/∂x + v∂u/∂y = -∂p/∂x + (1/Re)(∂²u/∂x² + ∂²u/∂y²)\n",
    "        momentum_u = (derivatives['u_t'] + \n",
    "                     derivatives['u'] * derivatives['u_x'] + \n",
    "                     derivatives['v'] * derivatives['u_y'] +\n",
    "                     derivatives['p_x'] -\n",
    "                     (1/Re) * (derivatives['u_xx'] + derivatives['u_yy']))\n",
    "        \n",
    "        # ∂v/∂t + u∂v/∂x + v∂v/∂y = -∂p/∂y + (1/Re)(∂²v/∂x² + ∂²v/∂y²)  \n",
    "        momentum_v = (derivatives['v_t'] +\n",
    "                     derivatives['u'] * derivatives['v_x'] +\n",
    "                     derivatives['v'] * derivatives['v_y'] +\n",
    "                     derivatives['p_y'] -\n",
    "                     (1/Re) * (derivatives['v_xx'] + derivatives['v_yy']))\n",
    "        \n",
    "        return continuity, momentum_u, momentum_v\n",
    "    \n",
    "    def ns_loss(params, x_pde, y_pde, t_pde, x_bc, y_bc, t_bc, u_bc, v_bc,\n",
    "                lambda_pde=1.0, lambda_bc=1.0):\n",
    "        \"\"\"Navier-Stokes PINN loss\"\"\"\n",
    "        \n",
    "        # PDE residuals\n",
    "        def compute_residuals(x, y, t):\n",
    "            return navier_stokes_residuals(params, x, y, t)\n",
    "        \n",
    "        residuals = vmap(compute_residuals)(x_pde, y_pde, t_pde)\n",
    "        continuity_loss = jnp.mean(residuals[0]**2)\n",
    "        momentum_u_loss = jnp.mean(residuals[1]**2) \n",
    "        momentum_v_loss = jnp.mean(residuals[2]**2)\n",
    "        pde_loss = continuity_loss + momentum_u_loss + momentum_v_loss\n",
    "        \n",
    "        # Boundary condition loss\n",
    "        def compute_bc_residuals(x, y, t, u_true, v_true):\n",
    "            derivatives = ns_forward(params, x, y, t)\n",
    "            u_pred, v_pred = derivatives['u'], derivatives['v']\n",
    "            return (u_pred - u_true)**2 + (v_pred - v_true)**2\n",
    "        \n",
    "        bc_residuals = vmap(compute_bc_residuals)(x_bc, y_bc, t_bc, u_bc, v_bc)\n",
    "        bc_loss = jnp.mean(bc_residuals)\n",
    "        \n",
    "        total_loss = lambda_pde * pde_loss + lambda_bc * bc_loss\n",
    "        \n",
    "        return total_loss, {\n",
    "            'pde_loss': pde_loss,\n",
    "            'continuity_loss': continuity_loss,\n",
    "            'momentum_u_loss': momentum_u_loss,\n",
    "            'momentum_v_loss': momentum_v_loss,\n",
    "            'bc_loss': bc_loss,\n",
    "            'total_loss': total_loss\n",
    "        }\n",
    "    \n",
    "    return init_params, ns_forward, ns_loss\n",
    "\n",
    "# Note: Navier-Stokes PINN is computationally intensive\n",
    "# This is a simplified demonstration setup\n",
    "\n",
    "print(\"\\nNavier-Stokes PINN Setup:\")\n",
    "init_ns_params, ns_forward_fn, ns_loss_fn = create_navier_stokes_pinn()\n",
    "ns_params = init_ns_params(random.PRNGKey(131415))\n",
    "\n",
    "# Generate minimal training data for demonstration\n",
    "key = random.PRNGKey(161718)\n",
    "n_pde_ns = 1000  # Reduced for demonstration\n",
    "n_bc_ns = 100\n",
    "\n",
    "# Domain: [0,1] × [0,1] × [0,0.1]\n",
    "x_pde_ns = random.uniform(key, (n_pde_ns,))\n",
    "y_pde_ns = random.uniform(random.split(key)[0], (n_pde_ns,))\n",
    "t_pde_ns = random.uniform(random.split(key)[1], (n_pde_ns,)) * 0.1\n",
    "\n",
    "# Boundary conditions (simplified: no-slip walls)\n",
    "x_bc_ns = random.uniform(random.split(key)[2], (n_bc_ns,))\n",
    "y_bc_ns = jnp.zeros(n_bc_ns)  # Bottom wall\n",
    "t_bc_ns = random.uniform(random.split(key)[3], (n_bc_ns,)) * 0.1\n",
    "u_bc_ns = jnp.zeros(n_bc_ns)  # No-slip condition\n",
    "v_bc_ns = jnp.zeros(n_bc_ns)\n",
    "\n",
    "# Test NS loss computation\n",
    "ns_loss, ns_info = ns_loss_fn(ns_params, x_pde_ns, y_pde_ns, t_pde_ns,\n",
    "                              x_bc_ns, y_bc_ns, t_bc_ns, u_bc_ns, v_bc_ns)\n",
    "\n",
    "print(f\"Initial NS losses:\")\n",
    "print(f\"Total loss: {ns_loss:.6f}\")\n",
    "print(f\"PDE loss: {ns_info['pde_loss']:.6f}\")\n",
    "print(f\"Continuity loss: {ns_info['continuity_loss']:.6f}\")\n",
    "print(f\"Momentum U loss: {ns_info['momentum_u_loss']:.6f}\")  \n",
    "print(f\"Momentum V loss: {ns_info['momentum_v_loss']:.6f}\")\n",
    "print(f\"BC loss: {ns_info['bc_loss']:.6f}\")\n",
    "\n",
    "# Test forward pass\n",
    "test_derivatives = ns_forward_fn(ns_params, 0.5, 0.5, 0.05)\n",
    "print(f\"\\nSample derivatives at (0.5, 0.5, 0.05):\")\n",
    "print(f\"u: {test_derivatives['u']:.6f}, v: {test_derivatives['v']:.6f}, p: {test_derivatives['p']:.6f}\")\n",
    "```\n",
    "\n",
    "## PINN with Adaptive Weights\n",
    "\n",
    "```python\n",
    "def create_adaptive_weight_pinn():\n",
    "    \"\"\"PINN with adaptive loss weighting for better convergence\"\"\"\n",
    "    \n",
    "    def adaptive_loss_weights(losses_history, method='grad_norm'):\n",
    "        \"\"\"Compute adaptive weights based on loss history\"\"\"\n",
    "        if len(losses_history) < 2:\n",
    "            return {'pde': 1.0, 'bc': 1.0, 'ic': 1.0}\n",
    "        \n",
    "        recent_losses = losses_history[-1]\n",
    "        \n",
    "        if method == 'grad_norm':\n",
    "            # Weight inversely proportional to gradient magnitudes\n",
    "            pde_loss, bc_loss, ic_loss = recent_losses['pde_loss'], recent_losses['bc_loss'], recent_losses['ic_loss']\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            pde_weight = 1.0 / (pde_loss + 1e-8)\n",
    "            bc_weight = 1.0 / (bc_loss + 1e-8) \n",
    "            ic_weight = 1.0 / (ic_loss + 1e-8)\n",
    "            \n",
    "            # Normalize weights\n",
    "            total_weight = pde_weight + bc_weight + ic_weight\n",
    "            return {\n",
    "                'pde': pde_weight / total_weight * 3,  # Scale to maintain total ~3\n",
    "                'bc': bc_weight / total_weight * 3,\n",
    "                'ic': ic_weight / total_weight * 3\n",
    "            }\n",
    "        \n",
    "        elif method == 'max_loss':\n",
    "            # Give higher weight to the largest loss component\n",
    "            losses = [recent_losses['pde_loss'], recent_losses['bc_loss'], recent_losses['ic_loss']]\n",
    "            max_loss = max(losses)\n",
    "            \n",
    "            return {\n",
    "                'pde': max_loss / (recent_losses['pde_loss'] + 1e-8),\n",
    "                'bc': max_loss / (recent_losses['bc_loss'] + 1e-8),\n",
    "                'ic': max_loss / (recent_losses['ic_loss'] + 1e-8)\n",
    "            }\n",
    "    \n",
    "    def train_with_adaptive_weights(init_params, loss_fn, training_data, \n",
    "                                   n_epochs=3000, lr=1e-3, adapt_freq=100):\n",
    "        \"\"\"Train PINN with adaptive weight adjustment\"\"\"\n",
    "        \n",
    "        x_pde, t_pde, x_bc, t_bc, x_ic = training_data\n",
    "        \n",
    "        # Initialize\n",
    "        params = init_params\n",
    "        opt_state = {'m': jax.tree_map(jnp.zeros_like, params),\n",
    "                    'v': jax.tree_map(jnp.zeros_like, params),\n",
    "                    'step': 0}\n",
    "        \n",
    "        losses_history = []\n",
    "        weight_history = []\n",
    "        \n",
    "        @jit\n",
    "        def train_step_adaptive(params, opt_state, lambda_pde, lambda_bc, lambda_ic):\n",
    "            def loss_fn_weighted(p):\n",
    "                return loss_fn(p, x_pde, t_pde, x_bc, t_bc, x_ic, \n",
    "                              lambda_pde, lambda_bc, lambda_ic)[0]\n",
    "            \n",
    "            loss, grads = jax.value_and_grad(loss_fn_weighted)(params)\n",
    "            \n",
    "            # Adam update\n",
    "            step = opt_state['step'] + 1\n",
    "            m = jax.tree_map(lambda m, g: 0.9 * m + 0.1 * g, opt_state['m'], grads)\n",
    "            v = jax.tree_map(lambda v, g: 0.999 * v + 0.001 * g**2, opt_state['v'], grads)\n",
    "            \n",
    "            m_hat = jax.tree_map(lambda m: m / (1 - 0.9**step), m)\n",
    "            v_hat = jax.tree_map(lambda v: v / (1 - 0.999**step), v)\n",
    "            \n",
    "            new_params = jax.tree_map(\n",
    "                lambda p, m, v: p - lr * m / (jnp.sqrt(v) + 1e-8),\n",
    "                params, m_hat, v_hat\n",
    "            )\n",
    "            \n",
    "            new_opt_state = {'m': m, 'v': v, 'step': step}\n",
    "            return new_params, new_opt_state, loss\n",
    "        \n",
    "        # Initial weights\n",
    "        weights = {'pde': 1.0, 'bc': 1.0, 'ic': 1.0}\n",
    "        \n",
    "        print(\"Training with Adaptive Weights:\")\n",
    "        print(\"Epoch | Total Loss | PDE λ | BC λ  | IC λ\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # Training step\n",
    "            params, opt_state, total_loss = train_step_adaptive(\n",
    "                params, opt_state, weights['pde'], weights['bc'], weights['ic']\n",
    "            )\n",
    "            \n",
    "            # Record losses for adaptation\n",
    "            if epoch % 50 == 0:  # Less frequent loss computation\n",
    "                _, info = loss_fn(params, x_pde, t_pde, x_bc, t_bc, x_ic)\n",
    "                losses_history.append(info)\n",
    "                weight_history.append(weights.copy())\n",
    "                \n",
    "                # Adapt weights\n",
    "                if epoch > 0 and epoch % adapt_freq == 0:\n",
    "                    weights = adaptive_loss_weights(losses_history)\n",
    "                \n",
    "                if epoch % 500 == 0:\n",
    "                    print(f\"{epoch:5d} | {total_loss:10.6f} | {weights['pde']:5.2f} | \"\n",
    "                          f\"{weights['bc']:5.2f} | {weights['ic']:5.2f}\")\n",
    "        \n",
    "        return params, losses_history, weight_history\n",
    "    \n",
    "    return train_with_adaptive_weights, adaptive_loss_weights\n",
    "\n",
    "# Test adaptive weight training\n",
    "adaptive_train_fn, adaptive_weights_fn = create_adaptive_weight_pinn()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ADAPTIVE WEIGHT PINN TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Use smaller problem for demonstration\n",
    "small_heat_params = init_heat_params(random.PRNGKey(192021))\n",
    "small_training_data = (x_pde[:1000], t_pde[:1000], x_bc[:50], t_bc[:50], x_ic[:50])\n",
    "\n",
    "# Train with adaptive weights\n",
    "adaptive_params, adaptive_losses, adaptive_weights = adaptive_train_fn(\n",
    "    small_heat_params, heat_loss_fn, small_training_data, n_epochs=1000, adapt_freq=200\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal adaptive weights:\")\n",
    "final_weights = adaptive_weights[-1]\n",
    "for name, weight in final_weights.items():\n",
    "    print(f\"  {name}: {weight:.3f}\")\n",
    "```\n",
    "\n",
    "## Multi-Scale PINN for Complex Domains\n",
    "\n",
    "```python\n",
    "def create_multiscale_pinn():\n",
    "    \"\"\"Multi-scale PINN for problems with multiple length/time scales\"\"\"\n",
    "    \n",
    "    def multiscale_encoding(x, t, scales=[1, 2, 4, 8]):\n",
    "        \"\"\"Multi-scale Fourier feature encoding\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for scale in scales:\n",
    "            # Fourier features for x\n",
    "            features.extend([\n",
    "                jnp.sin(2 * jnp.pi * scale * x),\n",
    "                jnp.cos(2 * jnp.pi * scale * x)\n",
    "            ])\n",
    "            \n",
    "            # Fourier features for t  \n",
    "            features.extend([\n",
    "                jnp.sin(2 * jnp.pi * scale * t),\n",
    "                jnp.cos(2 * jnp.pi * scale * t)\n",
    "            ])\n",
    "        \n",
    "        return jnp.array(features)\n",
    "    \n",
    "    def create_multiscale_network(base_dim=2, n_scales=4, hidden_dims=[128, 128, 128]):\n",
    "        \"\"\"Create network with multiscale inputs\"\"\"\n",
    "        \n",
    "        # Input dimension: base_dim + 4 * n_scales (sin/cos for each variable and scale)\n",
    "        input_dim = base_dim + 4 * n_scales\n",
    "        layer_sizes = [input_dim] + hidden_dims + [1]\n",
    "        \n",
    "        init_params, forward = create_pinn_model(layer_sizes)\n",
    "        \n",
    "        def multiscale_forward(params, x, t):\n",
    "            # Create multiscale features\n",
    "            ms_features = multiscale_encoding(x, t)\n",
    "            \n",
    "            # Concatenate with original inputs\n",
    "            full_input = jnp.concatenate([jnp.array([x, t]), ms_features])\n",
    "            \n",
    "            # Forward pass\n",
    "            return forward(params, full_input.reshape(1, -1))[0, 0]\n",
    "        \n",
    "        return init_params, multiscale_forward\n",
    "    \n",
    "    def create_domain_decomposition_pinn(n_subdomains=4):\n",
    "        \"\"\"Domain decomposition PINN\"\"\"\n",
    "        \n",
    "        # Create separate networks for each subdomain\n",
    "        subdomain_networks = []\n",
    "        for i in range(n_subdomains):\n",
    "            init_fn, forward_fn = create_pinn_model([2, 64, 64, 1])\n",
    "            subdomain_networks.append((init_fn, forward_fn))\n",
    "        \n",
    "        def init_dd_params(key):\n",
    "            keys = random.split(key, n_subdomains)\n",
    "            return [init_fn(k) for (init_fn, _), k in zip(subdomain_networks, keys)]\n",
    "        \n",
    "        def dd_forward(all_params, x, t):\n",
    "            \"\"\"Forward pass with domain decomposition\"\"\"\n",
    "            # Determine subdomain based on spatial location\n",
    "            subdomain_idx = int(x * n_subdomains)\n",
    "            subdomain_idx = jnp.clip(subdomain_idx, 0, n_subdomains - 1)\n",
    "            \n",
    "            # Use appropriate subdomain network\n",
    "            params = all_params[subdomain_idx]\n",
    "            _, forward_fn = subdomain_networks[subdomain_idx]\n",
    "            \n",
    "            return forward_fn(params, jnp.array([[x, t]]))[0, 0]\n",
    "        \n",
    "        def interface_continuity_loss(all_params, interfaces):\n",
    "            \"\"\"Enforce continuity at subdomain interfaces\"\"\"\n",
    "            continuity_loss = 0.0\n",
    "            \n",
    "            for i in range(len(interfaces)):\n",
    "                x_interface = interfaces[i]\n",
    "                \n",
    "                # Values from left and right subdomains\n",
    "                if i < n_subdomains - 1:\n",
    "                    left_val = all_params[i]  # Simplified\n",
    "                    right_val = all_params[i + 1]\n",
    "                    \n",
    "                    # This would compute actual interface values\n",
    "                    # continuity_loss += (left_val - right_val)**2\n",
    "            \n",
    "            return continuity_loss\n",
    "        \n",
    "        return init_dd_params, dd_forward, interface_continuity_loss\n",
    "    \n",
    "    return multiscale_encoding, create_multiscale_network, create_domain_decomposition_pinn\n",
    "\n",
    "# Test multiscale features\n",
    "ms_encoding, ms_network, dd_pinn = create_multiscale_pinn()\n",
    "\n",
    "# Test multiscale encoding\n",
    "x_test, t_test = 0.3, 0.1\n",
    "ms_features = ms_encoding(x_test, t_test)\n",
    "print(\"Multiscale Features:\")\n",
    "print(f\"Input: x={x_test}, t={t_test}\")\n",
    "print(f\"Multiscale features shape: {ms_features.shape}\")\n",
    "print(f\"Feature sample: {ms_features[:8]}\")  # First 8 features\n",
    "\n",
    "# Create multiscale network\n",
    "init_ms, forward_ms = ms_network()\n",
    "ms_params = init_ms(random.PRNGKey(222324))\n",
    "\n",
    "ms_output = forward_ms(ms_params, x_test, t_test)\n",
    "print(f\"Multiscale network output: {ms_output:.6f}\")\n",
    "\n",
    "# Test domain decomposition\n",
    "init_dd, forward_dd, interface_loss = dd_pinn(n_subdomains=2)\n",
    "dd_params = init_dd(random.PRNGKey(252627))\n",
    "\n",
    "dd_output = forward_dd(dd_params, x_test, t_test)\n",
    "print(f\"Domain decomposition output: {dd_output:.6f}\")\n",
    "```\n",
    "\n",
    "## PINN Performance Analysis and Validation\n",
    "\n",
    "```python\n",
    "def create_pinn_analysis_tools():\n",
    "    \"\"\"Tools for analyzing and validating PINN performance\"\"\"\n",
    "    \n",
    "    def compute_error_metrics(pinn_solution, analytical_solution, domain_points):\n",
    "        \"\"\"Compute various error metrics\"\"\"\n",
    "        \n",
    "        # Evaluate solutions at domain points\n",
    "        pinn_vals = jnp.array([pinn_solution(x, t) for x, t in domain_points])\n",
    "        analytical_vals = jnp.array([analytical_solution(x, t) for x, t in domain_points])\n",
    "        \n",
    "        # Error metrics\n",
    "        absolute_error = jnp.abs(pinn_vals - analytical_vals)\n",
    "        relative_error = absolute_error / (jnp.abs(analytical_vals) + 1e-8)\n",
    "        \n",
    "        metrics = {\n",
    "            'l1_error': jnp.mean(absolute_error),\n",
    "            'l2_error': jnp.sqrt(jnp.mean(absolute_error**2)),\n",
    "            'linf_error': jnp.max(absolute_error),\n",
    "            'mean_relative_error': jnp.mean(relative_error),\n",
    "            'max_relative_error': jnp.max(relative_error)\n",
    "        }\n",
    "        \n",
    "        return metrics, absolute_error, relative_error\n",
    "    \n",
    "    def conservation_analysis(pinn_forward_fn, params, domain_points):\n",
    "        \"\"\"Analyze conservation properties\"\"\"\n",
    "        \n",
    "        def compute_conservation_quantities(x, t):\n",
    "            # This would compute conserved quantities specific to the PDE\n",
    "            # For heat equation: total energy\n",
    "            u_val, _, _, _ = pinn_forward_fn(params, x, t)\n",
    "            return u_val\n",
    "        \n",
    "        conservation_vals = jnp.array([compute_conservation_quantities(x, t) \n",
    "                                     for x, t in domain_points])\n",
    "        \n",
    "        # Analyze conservation over time\n",
    "        time_groups = {}\n",
    "        for i, (x, t) in enumerate(domain_points):\n",
    "            t_key = round(float(t), 3)\n",
    "            if t_key not in time_groups:\n",
    "                time_groups[t_key] = []\n",
    "            time_groups[t_key].append(conservation_vals[i])\n",
    "        \n",
    "        conservation_analysis = {}\n",
    "        for t_key, vals in time_groups.items():\n",
    "            conservation_analysis[t_key] = {\n",
    "                'mean': jnp.mean(jnp.array(vals)),\n",
    "                'std': jnp.std(jnp.array(vals)),\n",
    "                'total': jnp.sum(jnp.array(vals))\n",
    "            }\n",
    "        \n",
    "        return conservation_analysis\n",
    "    \n",
    "    def residual_analysis(pinn_residual_fn, params, test_points):\n",
    "        \"\"\"Analyze PDE residuals across domain\"\"\"\n",
    "        \n",
    "        residuals = jnp.array([pinn_residual_fn(params, x, t) for x, t in test_points])\n",
    "        \n",
    "        residual_stats = {\n",
    "            'mean_residual': jnp.mean(jnp.abs(residuals)),\n",
    "            'max_residual': jnp.max(jnp.abs(residuals)),\n",
    "            'residual_std': jnp.std(residuals),\n",
    "            'residuals': residuals\n",
    "        }\n",
    "        \n",
    "        return residual_stats\n",
    "    \n",
    "    def boundary_condition_analysis(pinn_forward_fn, params, boundary_points, true_bc_values):\n",
    "        \"\"\"Analyze boundary condition satisfaction\"\"\"\n",
    "        \n",
    "        predicted_bc = jnp.array([pinn_forward_fn(params, x, t)[0] for x, t in boundary_points])\n",
    "        \n",
    "        bc_errors = jnp.abs(predicted_bc - true_bc_values)\n",
    "        \n",
    "        bc_analysis = {\n",
    "            'mean_bc_error': jnp.mean(bc_errors),\n",
    "            'max_bc_error': jnp.max(bc_errors),\n",
    "            'bc_satisfaction_rate': jnp.mean(bc_errors < 1e-3)  # Threshold for \"satisfied\"\n",
    "        }\n",
    "        \n",
    "        return bc_analysis\n",
    "    \n",
    "    return compute_error_metrics, conservation_analysis, residual_analysis, boundary_condition_analysis\n",
    "\n",
    "# Comprehensive PINN validation\n",
    "error_metrics_fn, conservation_fn, residual_fn, bc_analysis_fn = create_pinn_analysis_tools()\n",
    "\n",
    "# Create validation dataset\n",
    "validation_x = jnp.linspace(0, 1, 21)\n",
    "validation_t = jnp.linspace(0, 0.3, 16)\n",
    "validation_points = [(x, t) for x in validation_x for t in validation_t]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PINN VALIDATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Define PINN solution function\n",
    "def pinn_solution(x, t):\n",
    "    val, _, _, _ = heat_forward(trained_params, x, t)\n",
    "    return val\n",
    "\n",
    "# Compute error metrics\n",
    "metrics, abs_errors, rel_errors = error_metrics_fn(\n",
    "    pinn_solution, analytical_heat_solution, validation_points\n",
    ")\n",
    "\n",
    "print(\"Error Metrics vs Analytical Solution:\")\n",
    "for name, value in metrics.items():\n",
    "    print(f\"  {name}: {value:.6f}\")\n",
    "\n",
    "# Residual analysis\n",
    "def heat_residual(params, x, t):\n",
    "    return heat_pde_residual(params, x, t, alpha=0.01)\n",
    "\n",
    "residual_stats = residual_fn(heat_residual, trained_params, validation_points)\n",
    "print(f\"\\nPDE Residual Analysis:\")\n",
    "print(f\"  Mean residual: {residual_stats['mean_residual']:.6f}\")\n",
    "print(f\"  Max residual: {residual_stats['max_residual']:.6f}\")\n",
    "print(f\"  Residual std: {residual_stats['residual_std']:.6f}\")\n",
    "\n",
    "# Boundary condition analysis\n",
    "boundary_points_val = [(0.0, t) for t in validation_t] + [(1.0, t) for t in validation_t]\n",
    "boundary_true_vals = jnp.zeros(len(boundary_points_val))  # u=0 at boundaries\n",
    "\n",
    "bc_stats = bc_analysis_fn(heat_forward, trained_params, boundary_points_val, boundary_true_vals)\n",
    "print(f\"\\nBoundary Condition Analysis:\")\n",
    "print(f\"  Mean BC error: {bc_stats['mean_bc_error']:.6f}\")\n",
    "print(f\"  Max BC error: {bc_stats['max_bc_error']:.6f}\")\n",
    "print(f\"  BC satisfaction rate: {bc_stats['bc_satisfaction_rate']:.3f}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"  Overall L2 error: {metrics['l2_error']:.6f}\")\n",
    "print(f\"  Physics violation (residual): {residual_stats['mean_residual']:.6f}\")\n",
    "print(f\"  Boundary compliance: {bc_stats['bc_satisfaction_rate']*100:.1f}%\")\n",
    "\n",
    "if metrics['l2_error'] < 0.01 and residual_stats['mean_residual'] < 0.1:\n",
    "    print(\"  ✓ PINN solution appears accurate and physically consistent\")\n",
    "else:\n",
    "    print(\"  ⚠ PINN may need further training or architecture adjustment\")\n",
    "```\n",
    "\n",
    "## Summary\n",
    "\n",
    "This capstone project demonstrated Physics-Informed Neural Networks (PINNs) in JAX:\n",
    "\n",
    "**Core PINN Concepts:**\n",
    "- **Physics Integration**: Incorporating PDEs directly into loss functions\n",
    "- **Automatic Differentiation**: Computing derivatives for PDE residuals\n",
    "- **Multi-Objective Optimization**: Balancing PDE, boundary, and initial conditions\n",
    "- **Collocation Methods**: Using scattered points instead of structured grids\n",
    "\n",
    "**Implemented Solutions:**\n",
    "- **1D Heat Equation**: Parabolic PDE with analytical validation\n",
    "- **2D Poisson Equation**: Elliptic PDE with Dirichlet boundaries\n",
    "- **Navier-Stokes**: Complex fluid dynamics system\n",
    "- **Adaptive Weighting**: Dynamic loss component balancing\n",
    "\n",
    "**Advanced Techniques:**\n",
    "- **Multi-Scale Encoding**: Fourier features for multiple scales\n",
    "- **Domain Decomposition**: Splitting complex domains\n",
    "- **Conservation Analysis**: Verifying physical consistency\n",
    "- **Error Metrics**: Comprehensive validation tools\n",
    "\n",
    "**Key Advantages:**\n",
    "- **Mesh-Free**: No grid discretization required\n",
    "- **Flexible Boundaries**: Handle complex geometries easily\n",
    "- **Data-Efficient**: Physics provides regularization\n",
    "- **Inverse Problems**: Can solve for unknown parameters\n",
    "\n",
    "**Applications:**\n",
    "- **Engineering**: Heat transfer, fluid flow, structural mechanics\n",
    "- **Physics**: Wave propagation, quantum mechanics, plasma physics\n",
    "- **Finance**: Option pricing, risk modeling\n",
    "- **Biology**: Population dynamics, epidemiology\n",
    "\n",
    "**Best Practices:**\n",
    "- Use adaptive loss weighting for balanced training\n",
    "- Employ multi-scale features for complex phenomena\n",
    "- Validate against analytical solutions when available\n",
    "- Monitor PDE residuals and conservation laws\n",
    "- Consider domain decomposition for large problems\n",
    "\n",
    "PINNs represent a powerful paradigm shift in computational physics, enabling the solution of PDEs through machine learning while respecting fundamental physical principles."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
